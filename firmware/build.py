#!/usr/bin/env python3

# This should be run manually whenever the video is changed, don't expect this to be often

# Taken and adapted from here:
# https://github.com/AlexandreSenpai/Bad-Apple/blob/main/run.py

from multiprocessing.pool import ThreadPool
from multiprocessing import cpu_count
from typing import Tuple
import time

import cv2
import tqdm
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import argparse


video_path = './assets/rickroll_square.mp4'
# video_path = './assets/bad-apple.mp4'
code_gen_path = './src/video.c'
files, ranks, leds = (8, 8, 8)
frame_skip = 1

parser = argparse.ArgumentParser(description="Generates video file for board")
parser.add_argument("-v", "--visual", action="store_true", help="Visualize frame")

args = parser.parse_args()

# Set 1
start_frame = 1
end_frame = 200
# Set 2
# start_frame = 326
# end_frame = 326*2
# Set 3
# start_frame = 326*2
# end_frame = 326*3
# Set 4
# start_frame = 326*3
# end_frame = 326*4
# Set 5
# start_frame = 326*4
# end_frame = 326*5
# Set 5
# start_frame = 326*5
# end_frame = 326*6
#

last_frame = None
pixels = []


def write_frame(frame_information: Tuple[int, cv2.VideoCapture]):

    order, frame = frame_information
    if args.visual:
        global last_frame
        last_frame = frame
    
    y, x, _ = frame.shape
    pixel_row = 0

    if args.visual:
        global pixels
        pixels += [[]]
    
    frame_str = '    {\n'
    for i in range(files):
        frame_str += '        {\n'
        for j in range(ranks):
            frame_str += '            {'
            for led in range(leds):
                x_cm = i * 5 + 2.5
                y_cm = j * 5 + 2.5
                led_theta = led * 2 * np.pi / 8 + np.pi
                if i <= 3 and j <= 3:
                    led_theta += np.pi / 2
                elif i > 3 and j <= 3:
                    led_theta += np.pi
                elif i > 3 and j > 3:
                    led_theta += 3 * np.pi / 2

                x_cm += 1.8 * np.cos(led_theta)
                y_cm += 1.8 * np.sin(led_theta)

                pixel = frame[int(np.round((1 - y_cm / 40) * y)), int(np.round(x_cm / 40 * x))]
                r = pixel[2]
                g = pixel[1]
                b = pixel[0]

                if args.visual:
                    pixels[-1] += [[x_cm, y_cm, r, g, b]]

                frame_str += f'0x{r:02x}{g:02x}{b:02x}'
                frame_str += ', '
            frame_str += '},\n'

        frame_str += '},\n'
    frame_str += '    },\n'

    return order, frame_str
    

def generate_frames(video: cv2.VideoCapture):
    success = True
    order = 0
    i = 0
    
    while success and i < end_frame:
        i += 1
        success, frame = video.read()
        if i < start_frame:
            continue

        if i % frame_skip != 0:
            continue

        if frame is None:
            break
        
        yield order, frame
        
        order += 1

if __name__ == '__main__':
    
    video = cv2.VideoCapture(video_path)
    frame_cnt = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    
    with ThreadPool(processes=cpu_count()) as pool:
        frames = list(tqdm.tqdm(pool.imap(write_frame, generate_frames(video)), total=min(frame_cnt, (end_frame-start_frame)/2)))
        pool.close()
        pool.join()

    if args.visual:

        # cv2.imshow('frame', last_frame)

        fig, ax = plt.subplots()
        scatter = ax.scatter([], [])
        ax.set_aspect('equal', adjustable='box')

        plt.xlim(0, 40)
        plt.ylim(0, 40)

        def update(pix):
            pix = np.array(pix)
            x = pix[:, 0]
            y = pix[:, 1]
            colors = pix[:, 2:] / 255.0
            scatter.set_offsets(pix[:, 0:2])
            scatter.set_facecolors(colors)
            return scatter,

        # Create the animation
        ani = FuncAnimation(
            fig, update, frames=pixels, interval=1000 / (video.get(cv2.CAP_PROP_FPS) / frame_skip), blit=True
        )
        plt.show()
    
        
    frames = sorted(frames, key=lambda x: x[0])
    
    with open(code_gen_path, 'w') as f:
        f.write('// This is an autogenerated array of pixel data made through build.py, do not edit this manually\n')
        # f.write('use tdriver::graphics;\n')
        # f.write(f'pub const FRAMES: [[[u32; graphics::WORDS]; graphics::HEIGHT]; {len(frames)}] = [\n')

        f.write(f'#include <stdint.h>\n')
        f.write(f'#include <Arduino.h>\n')
        f.write(f'#include <video_config.h>\n')
        f.write('\n')
        f.write(f'const uint32_t num_frames = {len(frames)};\n')
        f.write(f'const float frame_rate = {video.get(cv2.CAP_PROP_FPS) / frame_skip};\n')
        f.write('\n')
        f.write(f'#if LINK_VIDEO\n')
        f.write('\n')
        f.write(f'const uint32_t frames[{len(frames)}][{files}][{ranks}][{leds}] PROGMEM = {{\n')
        for _, frame in frames:
            f.write(frame)
        f.write('};\n')
        f.write(f'#else\n')
        f.write(f'const uint32_t frames[0][{files}][{ranks}][{leds}] PROGMEM = {{}};\n')
        f.write(f'#endif\n')
